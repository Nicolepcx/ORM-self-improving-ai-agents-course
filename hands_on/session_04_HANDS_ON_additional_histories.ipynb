{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Open Notebook & Additional Resources\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Nicolepcx/ORM-self-improving-ai-agents-course/blob/main/hands_on/session_04_HANDS_ON_additional_histories.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "<a target=\"_blank\" href=\"https://learning.oreilly.com/library/view/ai-agents-the/0642572247775/\">\n",
        "  <img src=\"https://img.shields.io/badge/AI%20Agents%20Book-Read%20on%20O'Reilly-d40101?style=flat\" alt=\"AI Agents Book â€“ Read on O'Reilly\"/>\n",
        "</a>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w6wSWmHuszMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\" size=\"10\">\n",
        "<b>HANDS-ON TIME: 15 mins</b>\n",
        "</font>"
      ],
      "metadata": {
        "id": "E6kAJpe1Pe6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About this Notebook\n",
        "\n",
        "## What to do first (read this now)\n",
        "\n",
        "During the live session, **you do NOT need to read everything below**.\n",
        "\n",
        "**What you should do right now:**\n",
        "\n",
        "1. **Run the notebook as is**\n",
        "2. Look at the three example trajectories:\n",
        "   - Preserving special tokens\n",
        "   - Sub-agent delegation\n",
        "   - History compaction\n",
        "3. Inspect:\n",
        "   - `messages_and_choices`\n",
        "   - `additional_histories`\n",
        "   - `metrics`\n",
        "4. Observe how *one logical task* can contain **multiple conversations**\n",
        "\n",
        "Thatâ€™s it.  \n",
        "No coding required during the session.\n",
        "\n",
        "ðŸ‘‰ **After the course**, come back and read the rest of this notebook for the deeper explanation of *why* this matters and *how* to use it in production systems.\n",
        "\n",
        "---\n",
        "\n",
        "## What this notebook is really about (read later)\n",
        "\n",
        "This notebook introduces **additional histories**, a mechanism for storing *more than one conversation* inside a single training trajectory.\n",
        "\n",
        "In real agent systems, the main user-facing conversation is often **not** where the work happens. Important behavior occurs in:\n",
        "\n",
        "* sub-agent conversations\n",
        "* tool-call traces\n",
        "* reasoning tokens removed by chat templates\n",
        "* long conversations that later get summarized\n",
        "\n",
        "If you only train on the final coordinator transcript, you lose the information that caused the reward. That breaks credit assignment and slows learning.\n",
        "\n",
        "Additional histories solve this by letting you attach those hidden or intermediate conversations directly to the trajectory.\n",
        "\n",
        "---\n",
        "\n",
        "## The three examples you just ran\n",
        "\n",
        "### 1. Preserving special tokens\n",
        "\n",
        "Some models or chat templates remove tokens like `<think>` from earlier turns.\n",
        "\n",
        "This example shows how to:\n",
        "* keep the original reasoning tokens\n",
        "* store a cleaned version separately\n",
        "* train on both\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Sub-agent delegation\n",
        "\n",
        "The coordinator delegates work to sub-agents.\n",
        "\n",
        "Instead of losing those conversations, they are stored as additional histories so the model can learn:\n",
        "* how to delegate\n",
        "* how to evaluate sub-agent output\n",
        "* how to combine results\n",
        "\n",
        "---\n",
        "\n",
        "### 3. History compaction\n",
        "\n",
        "Long-running agents often summarize past conversations.\n",
        "\n",
        "This example keeps:\n",
        "* the compacted summary in the main history\n",
        "* the original conversation in an additional history\n",
        "\n",
        "This preserves training signal without increasing runtime context.\n",
        "\n",
        "---\n",
        "\n",
        "## Evaluation note\n",
        "\n",
        "RULER does not support `additional_histories` yet.\n",
        "\n",
        "Thatâ€™s why evaluation in this notebook uses a simple reward function over the main trajectory only.  \n",
        "Additional histories are currently meant for **training signal**, not evaluation.\n",
        "\n",
        "---\n",
        "\n",
        "## One takeaway\n",
        "\n",
        "If you remember one thing:\n",
        "\n",
        "**The final chat transcript is not the full behavior of an agent.  \n",
        "Additional histories are how you train on what actually happened.**\n"
      ],
      "metadata": {
        "id": "rqUVSl4aKvNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timer"
      ],
      "metadata": {
        "id": "do98lvgEg-FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SET_TIMER = False  # False, True, or minutes as a number\n",
        "\n",
        "import requests, types\n",
        "url = \"https://raw.githubusercontent.com/Nicolepcx/ORM-self-improving-ai-agents-course/main/timer.py\"\n",
        "\n",
        "timer = types.ModuleType(\"timer\")\n",
        "exec(requests.get(url).text, timer.__dict__)\n",
        "\n",
        "timer.start_exam_timer(enabled=SET_TIMER, minutes=15, warn_minutes=5)"
      ],
      "metadata": {
        "id": "EkqpHLlVfcL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PeF9Q-k0cYlQ"
      },
      "outputs": [],
      "source": [
        "# @title Installation\n",
        "# Portions adapted from Unsloth Notebooks (https://github.com/unslothai/notebooks)\n",
        "# Copyright (c) Unsloth contributors.\n",
        "# License: GNU LGPL v3.0.\n",
        "# Modifications by OpenPipe:\n",
        "# See /licenses/LGPL-3.0.txt and /licenses/GPL-3.0.txt for full text.\n",
        "\n",
        "%%capture\n",
        "import os\n",
        "\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !uv pip install openpipe-art[backend]==0.4.11 tenacity \"mcp>=1.11.0\" \"gql<4\" aiohttp --prerelease allow --no-cache-dir\n",
        "else:\n",
        "    try:\n",
        "        import numpy\n",
        "\n",
        "        get_numpy = f\"numpy=={numpy.__version__}\"\n",
        "    except:\n",
        "        get_numpy = \"numpy\"\n",
        "    try:\n",
        "        import subprocess\n",
        "\n",
        "        is_t4 = \"Tesla T4\" in str(subprocess.check_output([\"nvidia-smi\"]))\n",
        "    except:\n",
        "        is_t4 = False\n",
        "    get_vllm, get_triton = (\n",
        "        (\"vllm==0.9.2\", \"triton==3.2.0\") if is_t4 else (\"vllm\", \"triton\")\n",
        "    )\n",
        "    !uv pip install --upgrade \\\n",
        "        openpipe-art[backend]==0.4.11 tenacity pillow==11.3.0 protobuf==5.29.5 {get_vllm} {get_numpy} --prerelease allow --no-cache-dir\n",
        "    !uv pip install -qqq {get_triton}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "paqYU2iQKsH4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PBH9Q-RlcYlS"
      },
      "outputs": [],
      "source": [
        "import art\n",
        "from art.trajectories import Trajectory, History, Choice\n",
        "from openai.types.chat import ChatCompletionMessage\n",
        "from art.utils.logging import info, ok, step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZNAwkuPcYlS"
      },
      "source": [
        "## Why Additional Histories?\n",
        "\n",
        "In a multi-agent system, if you only train on the main coordinator conversation, the model sees:\n",
        "- âœ… The final output\n",
        "- âŒ But NOT the sub-agent reasoning, actions, and intermediate steps\n",
        "\n",
        "This breaks **credit assignment** - the model can't learn:\n",
        "- How to delegate effectively\n",
        "- How to verify sub-agent work\n",
        "- How to compose results from multiple agents\n",
        "\n",
        "By storing each sub-agent conversation as an **additional history**, you give the RL training process:\n",
        "- The functions and actions each sub-agent used\n",
        "- The intermediate signals and reasoning\n",
        "- Clear attribution of what led to the final reward\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hands-on"
      ],
      "metadata": {
        "id": "CUx_cSmre3To"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHCabs1Avcdu"
      },
      "source": [
        "<font color=\"red\" size=\"10\">\n",
        "<b>TODO: </b>\n",
        "</font>\n",
        "<br>\n",
        "<font color=\"black\" size=\"5\">\n",
        "<b>Create Trajectories with Additional Histories</b>\n",
        "</font>\n",
        "\n",
        "\n",
        "In this hands-on, you'll create three different trajectories (just run the notebook) demonstrating the use cases for additional histories:\n",
        "\n",
        "1. **Preserving Special Tokens** - Keep reasoning tokens across multi-turn conversations\n",
        "2. **Sub-Agent Delegation** - Train on both coordinator and sub-agent conversations\n",
        "3. **History Compaction** - Preserve original conversation before summarization\n",
        "\n",
        "You'll also see how to evaluate trajectories without RULER (since RULER doesn't support additional histories yet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnAh7bPsvcdu",
        "outputId": "a9179a55-346f-4e1c-e0ce-88236fca60a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1: Preserving Special Tokens\n",
            "============================================================\n",
            "Primary history messages: 2\n",
            "Additional histories: 1\n",
            "Reward: 0.9\n",
            "\n",
            "Primary history:\n",
            "  user: What is 2+2?...\n",
            "  Choice: <think>I need to add 2 and 2</think>4...\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Preserving Special Tokens in Multi-Turn Conversations\n",
        "# Some models remove special tokens like <think> from previous turns\n",
        "# By using additional histories, we can preserve these tokens for training\n",
        "\n",
        "from art.trajectories import Trajectory, History, Choice\n",
        "from openai.types.chat import ChatCompletionMessage\n",
        "\n",
        "trajectory_preserve_tokens = Trajectory(\n",
        "    messages_and_choices=[\n",
        "        # First turn with thinking preserved\n",
        "        {\"role\": \"user\", \"content\": \"What is 2+2?\"},\n",
        "        Choice(\n",
        "            index=0,\n",
        "            finish_reason=\"stop\",\n",
        "            message=ChatCompletionMessage(\n",
        "                role=\"assistant\",\n",
        "                content=\"<think>I need to add 2 and 2</think>4\",\n",
        "            ),\n",
        "        ),\n",
        "    ],\n",
        "    additional_histories=[\n",
        "        History(\n",
        "            messages_and_choices=[\n",
        "                # The Qwen 3 chat template removes <think> tokens from previous turns\n",
        "                # So we store the \"cleaned\" version in an additional history\n",
        "                {\"role\": \"user\", \"content\": \"What is 2+2?\"},\n",
        "                Choice(\n",
        "                    index=0,\n",
        "                    finish_reason=\"stop\",\n",
        "                    message=ChatCompletionMessage(role=\"assistant\", content=\"4\"),\n",
        "                ),\n",
        "                {\"role\": \"user\", \"content\": \"What is 3+3?\"},\n",
        "                Choice(\n",
        "                    index=0,\n",
        "                    finish_reason=\"stop\",\n",
        "                    message=ChatCompletionMessage(\n",
        "                        role=\"assistant\",\n",
        "                        content=\"<think>I need to add 3 and 3</think>6\",\n",
        "                    ),\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "    ],\n",
        "    reward=0.9,\n",
        "    metrics={\"preserved_reasoning_tokens\": True},\n",
        ")\n",
        "\n",
        "print(\"Example 1: Preserving Special Tokens\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Primary history messages: {len(trajectory_preserve_tokens.messages_and_choices)}\")\n",
        "print(f\"Additional histories: {len(trajectory_preserve_tokens.additional_histories)}\")\n",
        "print(f\"Reward: {trajectory_preserve_tokens.reward}\")\n",
        "print(\"\\nPrimary history:\")\n",
        "for msg in trajectory_preserve_tokens.messages_and_choices:\n",
        "    if isinstance(msg, dict):\n",
        "        print(f\"  {msg['role']}: {msg['content'][:80]}...\")\n",
        "    else:\n",
        "        content = msg.message.content if msg.message.content else \"\"\n",
        "        print(f\"  Choice: {content[:80]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5WIEFDtvcdu"
      },
      "source": [
        "## Example 2: Training Agents That Call Sub-Agents (Sub-Agent Delegation)\n",
        "\n",
        "When an agent delegates work to sub-agents, each sub-agent conversation can be stored as an additional history. This allows the model to learn from both the main conversation flow and the sub-agent interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYS3ngabvcdu",
        "outputId": "99a1a67f-afdd-42c7-d7a4-50c3e9ee5778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 2: Sub-Agents\n",
            "============================================================\n",
            "Primary history messages: 6\n",
            "Additional histories: 2\n",
            "Reward: 0.85\n",
            "Metrics: {'sub_agents_used': 2, 'bugs_found': 3, 'bugs_fixed': 1, 'task_completed': True}\n",
            "\n",
            "Sub-agents:\n",
            "\n",
            "  Sub-agent 1:\n",
            "    system: You are a code analysis expert. Analyze code for potential bugs....\n",
            "    user: Find potential bugs in main.py...\n",
            "    Choice: Found 3 potential issues:\n",
            "1. Null pointer on line 42\n",
            "2. Memory leak on line 87\n",
            "3. Uninitialized vari...\n",
            "\n",
            "  Sub-agent 2:\n",
            "    system: You are a bug fixing expert. Fix code issues safely and correctly....\n",
            "    user: Fix the null pointer issue on line 42...\n",
            "    Choice: Fixed by adding null check:\n",
            "```cpp\n",
            "if (ptr != nullptr) {\n",
            "    // safe to use ptr\n",
            "}\n",
            "```...\n"
          ]
        }
      ],
      "source": [
        "# Main agent delegates work to specialized sub-agents\n",
        "\n",
        "ANALYZE_ID = \"call_analyze_1\"\n",
        "FIX_ID = \"call_fix_1\"\n",
        "\n",
        "trajectory_sub_agents = Trajectory(\n",
        "    # Main agent conversation\n",
        "    messages_and_choices=[\n",
        "        {\"role\": \"user\", \"content\": \"Analyze this codebase and fix any bugs\"},\n",
        "\n",
        "        # Assistant tool call: analyze_code\n",
        "        Choice(\n",
        "            index=0,\n",
        "            finish_reason=\"tool_calls\",\n",
        "            message=ChatCompletionMessage(\n",
        "                role=\"assistant\",\n",
        "                content=None,\n",
        "                tool_calls=[\n",
        "                    {\n",
        "                        \"id\": ANALYZE_ID,\n",
        "                        \"type\": \"function\",\n",
        "                        \"function\": {\n",
        "                            \"name\": \"analyze_code\",\n",
        "                            \"arguments\": '{\"file\": \"main.py\", \"task\": \"Find potential bugs\"}',\n",
        "                        },\n",
        "                    }\n",
        "                ],\n",
        "            ),\n",
        "        ),\n",
        "\n",
        "        # Tool result for analyze_code\n",
        "        {\n",
        "            \"role\": \"tool\",\n",
        "            \"tool_call_id\": ANALYZE_ID,\n",
        "            \"content\": (\n",
        "                \"Found 3 potential issues: null pointer on line 42, \"\n",
        "                \"memory leak on line 87, uninitialized variable on line 120\"\n",
        "            ),\n",
        "        },\n",
        "\n",
        "        # Assistant tool call: fix_issues\n",
        "        Choice(\n",
        "            index=0,\n",
        "            finish_reason=\"tool_calls\",\n",
        "            message=ChatCompletionMessage(\n",
        "                role=\"assistant\",\n",
        "                content=None,\n",
        "                tool_calls=[\n",
        "                    {\n",
        "                        \"id\": FIX_ID,\n",
        "                        \"type\": \"function\",\n",
        "                        \"function\": {\n",
        "                            \"name\": \"fix_issues\",\n",
        "                            \"arguments\": '{\"issue\": \"null pointer on line 42\", \"fix\": \"Add null check\"}',\n",
        "                        },\n",
        "                    }\n",
        "                ],\n",
        "            ),\n",
        "        ),\n",
        "\n",
        "        # Tool result for fix_issues\n",
        "        {\n",
        "            \"role\": \"tool\",\n",
        "            \"tool_call_id\": FIX_ID,\n",
        "            \"content\": \"Fixed by adding null check: if (ptr != nullptr) { ... }\",\n",
        "        },\n",
        "\n",
        "        # Final assistant answer\n",
        "        Choice(\n",
        "            index=0,\n",
        "            finish_reason=\"stop\",\n",
        "            message=ChatCompletionMessage(\n",
        "                role=\"assistant\",\n",
        "                content=(\n",
        "                    \"I've analyzed the codebase and fixed the critical null pointer issue on line 42. \"\n",
        "                    \"The fix adds a null check before dereferencing the pointer.\"\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "    ],\n",
        "    additional_histories=[\n",
        "        # Sub-agent 1: Code analysis\n",
        "        History(\n",
        "            messages_and_choices=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a code analysis expert. Analyze code for potential bugs.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Find potential bugs in main.py\"},\n",
        "                Choice(\n",
        "                    index=0,\n",
        "                    finish_reason=\"stop\",\n",
        "                    message=ChatCompletionMessage(\n",
        "                        role=\"assistant\",\n",
        "                        content=(\n",
        "                            \"Found 3 potential issues:\\n\"\n",
        "                            \"1. Null pointer on line 42\\n\"\n",
        "                            \"2. Memory leak on line 87\\n\"\n",
        "                            \"3. Uninitialized variable on line 120\"\n",
        "                        ),\n",
        "                    ),\n",
        "                ),\n",
        "            ]\n",
        "        ),\n",
        "        # Sub-agent 2: Bug fixing\n",
        "        History(\n",
        "            messages_and_choices=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a bug fixing expert. Fix code issues safely and correctly.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Fix the null pointer issue on line 42\"},\n",
        "                Choice(\n",
        "                    index=0,\n",
        "                    finish_reason=\"stop\",\n",
        "                    message=ChatCompletionMessage(\n",
        "                        role=\"assistant\",\n",
        "                        content=(\n",
        "                            \"Fixed by adding null check:\\n\"\n",
        "                            \"```cpp\\n\"\n",
        "                            \"if (ptr != nullptr) {\\n\"\n",
        "                            \"    // safe to use ptr\\n\"\n",
        "                            \"}\\n\"\n",
        "                            \"```\"\n",
        "                        ),\n",
        "                    ),\n",
        "                ),\n",
        "            ]\n",
        "        ),\n",
        "    ],\n",
        "    reward=0.85,\n",
        "    metrics={\n",
        "        \"sub_agents_used\": 2,\n",
        "        \"bugs_found\": 3,\n",
        "        \"bugs_fixed\": 1,\n",
        "        \"task_completed\": True,\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"Example 2: Sub-Agents\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Primary history messages: {len(trajectory_sub_agents.messages_and_choices)}\")\n",
        "print(f\"Additional histories: {len(trajectory_sub_agents.additional_histories)}\")\n",
        "print(f\"Reward: {trajectory_sub_agents.reward}\")\n",
        "print(f\"Metrics: {trajectory_sub_agents.metrics}\")\n",
        "print(\"\\nSub-agents:\")\n",
        "for i, history in enumerate(trajectory_sub_agents.additional_histories, 1):\n",
        "    print(f\"\\n  Sub-agent {i}:\")\n",
        "    for msg in history.messages_and_choices:\n",
        "        if isinstance(msg, dict):\n",
        "            role = msg.get('role', 'unknown')\n",
        "            content = msg.get('content', '')[:100]\n",
        "            print(f\"    {role}: {content}...\")\n",
        "        else:\n",
        "            content = msg.message.content if msg.message.content else \"\"\n",
        "            print(f\"    Choice: {content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrFL4mvlvcdv"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3: History Compaction\n",
        "## Long-running agent that compresses conversation history periodically\n"
      ],
      "metadata": {
        "id": "CrgSeD2Sv7gG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7PlroMQvcdv",
        "outputId": "eec5d01e-c419-4436-9f23-b1aebb87b378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 3: History Compaction\n",
            "============================================================\n",
            "Primary history messages: 6\n",
            "Additional histories: 1\n",
            "Reward: 0.92\n",
            "Metrics: {'history_compacted': True, 'original_turns': 4, 'compacted_turns': 3}\n",
            "\n",
            "Original conversation (before compaction):\n",
            "  system: You are a helpful assistant....\n",
            "  user: Explain quantum entanglement...\n",
            "  Choice: Quantum entanglement is a phenomenon where two or more particles become correlated so that the quant...\n",
            "  user: Can you give me a simple example?...\n",
            "  Choice: Imagine two coins that are perfectly anti-correlated. If one is heads, the other is tails, every tim...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trajectory_compaction = Trajectory(\n",
        "    # Current active conversation (after compaction)\n",
        "    messages_and_choices=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Compacted conversation history: The user asked about quantum entanglement, and I explained the \"\n",
        "                \"basic concept of how particles can be correlated even when separated.\"\n",
        "            ),\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": \"Tell me more about the history of quantum entanglement\"},\n",
        "        Choice(\n",
        "            index=0,\n",
        "            finish_reason=\"stop\",\n",
        "            message=ChatCompletionMessage(\n",
        "                role=\"assistant\",\n",
        "                content=(\n",
        "                    \"Quantum entanglement was first proposed by Einstein, Podolsky, and Rosen in 1935 in what's now \"\n",
        "                    \"called the EPR paradox. They were concerned that quantum mechanics seemed to violate locality, \"\n",
        "                    \"the idea that objects can only be influenced by their immediate surroundings. However, \"\n",
        "                    \"experiments by John Bell in the 1960s and subsequent tests have confirmed that entanglement is \"\n",
        "                    \"a real physical phenomenon. Today, entanglement is a key resource in quantum computing and \"\n",
        "                    \"quantum cryptography.\"\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "        {\"role\": \"user\", \"content\": \"How is it used in quantum computing?\"},\n",
        "        Choice(\n",
        "            index=0,\n",
        "            finish_reason=\"stop\",\n",
        "            message=ChatCompletionMessage(\n",
        "                role=\"assistant\",\n",
        "                content=(\n",
        "                    \"In quantum computing, entanglement is used to create quantum gates that operate on multiple \"\n",
        "                    \"qubits simultaneously. For example, the CNOT gate creates entanglement between two qubits. \"\n",
        "                    \"This enables quantum algorithms to process information in ways that classical computers cannot. \"\n",
        "                    \"Some algorithms show large speedups for specific tasks, such as factoring (Shor's algorithm) or \"\n",
        "                    \"search (Grover's algorithm).\"\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "    ],\n",
        "    additional_histories=[\n",
        "        History(\n",
        "            messages_and_choices=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Explain quantum entanglement\"},\n",
        "                Choice(\n",
        "                    index=0,\n",
        "                    finish_reason=\"stop\",\n",
        "                    message=ChatCompletionMessage(\n",
        "                        role=\"assistant\",\n",
        "                        content=(\n",
        "                            \"Quantum entanglement is a phenomenon where two or more particles become correlated so \"\n",
        "                            \"that the quantum state of each particle cannot be described independently, even when the \"\n",
        "                            \"particles are separated by large distances. Measuring one particle lets you predict \"\n",
        "                            \"properties of the other, regardless of distance. This 'spooky action at a distance' \"\n",
        "                            \"(as Einstein called it) has been experimentally verified and is a fundamental aspect of \"\n",
        "                            \"quantum mechanics.\"\n",
        "                        ),\n",
        "                    ),\n",
        "                ),\n",
        "                {\"role\": \"user\", \"content\": \"Can you give me a simple example?\"},\n",
        "                Choice(\n",
        "                    index=0,\n",
        "                    finish_reason=\"stop\",\n",
        "                    message=ChatCompletionMessage(\n",
        "                        role=\"assistant\",\n",
        "                        content=(\n",
        "                            \"Imagine two coins that are perfectly anti-correlated. If one is heads, the other is \"\n",
        "                            \"tails, every time. If you separate them far apart, observing one instantly tells you \"\n",
        "                            \"what you'd observe for the other. This is only an analogy: real entanglement is not \"\n",
        "                            \"about hidden predetermined coin states, but it helps build intuition.\"\n",
        "                        ),\n",
        "                    ),\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "    ],\n",
        "    reward=0.92,\n",
        "    metrics={\n",
        "        \"history_compacted\": True,\n",
        "        \"original_turns\": 4,\n",
        "        \"compacted_turns\": 3,\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"Example 3: History Compaction\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Primary history messages: {len(trajectory_compaction.messages_and_choices)}\")\n",
        "print(f\"Additional histories: {len(trajectory_compaction.additional_histories)}\")\n",
        "print(f\"Reward: {trajectory_compaction.reward}\")\n",
        "print(f\"Metrics: {trajectory_compaction.metrics}\")\n",
        "print(\"\\nOriginal conversation (before compaction):\")\n",
        "for msg in trajectory_compaction.additional_histories[0].messages_and_choices:\n",
        "    if isinstance(msg, dict):\n",
        "        role = msg.get('role', 'unknown')\n",
        "        content = msg.get('content', '')[:100]\n",
        "        print(f\"  {role}: {content}...\")\n",
        "    else:\n",
        "        content = msg.message.content if msg.message.content else \"\"\n",
        "        print(f\"  Choice: {content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAHr8x-xvcdv"
      },
      "source": [
        "## Evaluating Trajectories with Additional Histories\n",
        "\n",
        "**Important:** RULER does not currently support trajectories with `additional_histories`. If you try to use RULER with additional histories, it will raise an error.\n",
        "\n",
        "Here are two approaches to work around this:\n",
        "\n",
        "1. **Use a simple reward function** - Evaluate based on the main trajectory only\n",
        "2. **Create simplified trajectories** - Extract just the main history for RULER evaluation, while keeping the full trajectory with additional histories for training\n",
        "\n",
        "Let's demonstrate both approaches:\n",
        "\n",
        "- Approach 1: Simple Reward Function\n",
        "- Evaluate trajectories based on their main conversation only\n",
        "- This works well when the additional histories are for training context, not evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7scLmEjWvcdv",
        "outputId": "531711cf-05dc-4bcb-eee0-a55d42ca491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SIMPLE REWARD FUNCTION EVALUATION\n",
            "================================================================================\n",
            "\n",
            "Preserve Tokens:\n",
            "  Computed reward: 0.000\n",
            "  Original reward: 0.9\n",
            "  Additional histories: 1\n",
            "  Metrics: {'preserved_reasoning_tokens': True}\n",
            "\n",
            "Sub-Agents:\n",
            "  Computed reward: 0.900\n",
            "  Original reward: 0.85\n",
            "  Additional histories: 2\n",
            "  Metrics: {'sub_agents_used': 2, 'bugs_found': 3, 'bugs_fixed': 1, 'task_completed': True}\n",
            "\n",
            "History Compaction:\n",
            "  Computed reward: 0.500\n",
            "  Original reward: 0.92\n",
            "  Additional histories: 1\n",
            "  Metrics: {'history_compacted': True, 'original_turns': 4, 'compacted_turns': 3}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def simple_reward_function(trajectory: Trajectory) -> float:\n",
        "    \"\"\"\n",
        "    A simple reward function that evaluates the main trajectory.\n",
        "    In practice, you'd use more sophisticated logic based on your task.\n",
        "    \"\"\"\n",
        "    # Extract the final assistant message from the main conversation\n",
        "    final_choice = None\n",
        "    for msg in reversed(trajectory.messages_and_choices):\n",
        "        if isinstance(msg, Choice):\n",
        "            final_choice = msg\n",
        "            break\n",
        "\n",
        "    if not final_choice or not final_choice.message.content:\n",
        "        return 0.0\n",
        "\n",
        "    content = final_choice.message.content.lower()\n",
        "    score = 0.0\n",
        "\n",
        "    # Simple heuristics (replace with your actual evaluation logic)\n",
        "    # For code tasks: check if solution mentions fixes\n",
        "    if \"fixed\" in content or \"fix\" in content:\n",
        "        score += 0.3\n",
        "    if \"null\" in content or \"bug\" in content:\n",
        "        score += 0.2\n",
        "\n",
        "    # For Q&A tasks: check if answer is substantive\n",
        "    if len(content) > 100:\n",
        "        score += 0.3\n",
        "    if \"quantum\" in content or \"entanglement\" in content:\n",
        "        score += 0.2\n",
        "\n",
        "    # Bonus for using sub-agents (if metrics indicate it)\n",
        "    if trajectory.metrics.get(\"sub_agents_used\", 0) > 0:\n",
        "        score += 0.1\n",
        "\n",
        "    return min(score, 1.0)\n",
        "\n",
        "# Evaluate our trajectories\n",
        "all_trajectories = [\n",
        "    (\"Preserve Tokens\", trajectory_preserve_tokens),\n",
        "    (\"Sub-Agents\", trajectory_sub_agents),\n",
        "    (\"History Compaction\", trajectory_compaction),\n",
        "]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"SIMPLE REWARD FUNCTION EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for name, traj in all_trajectories:\n",
        "    reward = simple_reward_function(traj)\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Computed reward: {reward:.3f}\")\n",
        "    print(f\"  Original reward: {traj.reward}\")\n",
        "    print(f\"  Additional histories: {len(traj.additional_histories)}\")\n",
        "    print(f\"  Metrics: {traj.metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T04fCg4ejCEW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}